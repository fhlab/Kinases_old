{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the initialization and imports\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import math\n",
    "import pprint\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "from Bio import SeqIO, AlignIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Emboss.Applications import NeedleallCommandline\n",
    "\n",
    "# Demand Python 3.\n",
    "if sys.version_info[0] < 3:\n",
    "    print(\"Python 3 is required, but you are using Python %i.%i.%i\") % (\n",
    "        sys.version_info[0], sys.version_info[1], sys.version_info[2])\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the specific functions from ind and proteins.py\n",
    "indels_path=\"/home/maya/InDelScanner\"  # /PATH/TO/InDelScanner\n",
    "if indels_path not in sys.path:\n",
    "    sys.path.append(indels_path)\n",
    "#from indels.ind import trim_read, findEnds, endMatch, findGap, gapAlign\n",
    "\n",
    "from ipynb.fs.defs.Library_diversity import convert_variant_to_dict\n",
    "\n",
    "os.chdir(\"/mnt/c/Users/Maya/Dropbox/mek_results\")\n",
    "\n",
    "with open('Remkes_protein.p', 'rb') as f:\n",
    "    all_ref = pickle.load(f)\n",
    "with open('Remkes_protein_low.p', 'rb') as f:\n",
    "    low = pickle.load(f)\n",
    "\n",
    "all_ref['mek']['low-v2'] = low['mek']['low-v2']\n",
    "\n",
    "mek = {}\n",
    "for fraction in ['high', 'med']:\n",
    "    mek[fraction] = Counter(all_ref['mek'][fraction])\n",
    "mek['low-t'] = Counter(all_ref['mek']['low']) + Counter(all_ref['mek']['low-v2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame.from_dict(mek).fillna(0).sort_values(by=['high', 'med', 'low-t'], ascending=False).astype(int)\n",
    "df_50p = df_all.loc[(df_all['high'] >= 50) & ((df_all['high']+df_all['med']) > 2*df_all['low-t'])]\n",
    "df_20to50 = df_all.loc[(df_all['high'].isin(range(10,50))) & \n",
    "                       (df_all['high'] > df_all['med']) & \n",
    "                       ((df_all['high']+df_all['med']) > 5*df_all['low-t']) ]\n",
    "\n",
    "df_pos = df_50p.append(df_20to50)\n",
    "\n",
    "active_ls = df_pos.index.tolist()\n",
    "active = {short : convert_variant_to_dict(short) for short in active_ls}\n",
    "\n",
    "valid_pos = ['6', '7a', '8a', '9', '11', '13']\n",
    "\n",
    "data = {}\n",
    "for short, m_to_pos in active.items():\n",
    "    if len(m_to_pos) != len(valid_pos):\n",
    "        continue\n",
    "    else:\n",
    "        data[short] = [m_to_pos[i] for i in valid_pos]\n",
    "\n",
    "factors = pd.DataFrame.from_dict(data, orient='index', columns=valid_pos).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = factors[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_variant_blosum_matrix(data_x, data_y=None, weight=None, cat_features=None):  \n",
    "    # data_x is going to be a dataframe (factors_df) with each factors a separate column\n",
    "    # df content is strings (categorical factors)\n",
    "    \n",
    "    # function checks\n",
    "    X = data_x\n",
    "    if data_y is None: Y = data_x \n",
    "    else: Y = data_y \n",
    "    if not isinstance(X, np.ndarray): \n",
    "        if not np.array_equal(X.columns, Y.columns): raise TypeError(\"X and Y must have same columns!\")   \n",
    "    else: \n",
    "         if not X.shape[1] == Y.shape[1]: raise TypeError(\"X and Y must have same y-dim!\")  \n",
    "                \n",
    "    if issparse(X) or issparse(Y): raise TypeError(\"Sparse matrices are not supported!\")        \n",
    "            \n",
    "    x_n_rows, x_n_cols = X.shape\n",
    "    y_n_rows, y_n_cols = Y.shape \n",
    "    \n",
    "    # determine which features are categorical\n",
    "    # get a boolean array for columns\n",
    "    if cat_features is None:\n",
    "        if not isinstance(X, np.ndarray): \n",
    "            is_number = np.vectorize(lambda x: not np.issubdtype(x, np.number))\n",
    "            cat_features = is_number(X.dtypes)    \n",
    "        else:\n",
    "            cat_features = np.zeros(x_n_cols, dtype=bool)\n",
    "            for col in range(x_n_cols):\n",
    "                if not np.issubdtype(type(X[0, col]), np.number):\n",
    "                    cat_features[col]=True\n",
    "    else:          \n",
    "        cat_features = np.array(cat_features)\n",
    "    \n",
    "    print(cat_features)\n",
    "    #\n",
    "    if not isinstance(X, np.ndarray): X = np.asarray(X)\n",
    "    if not isinstance(Y, np.ndarray): Y = np.asarray(Y)\n",
    "    \n",
    "    # concatenate, that is attach one after the other (keep same columns)\n",
    "    Z = np.concatenate((X,Y))\n",
    "    \n",
    "    # the indices run over different rows of the same array - slicing\n",
    "    x_index = range(0,x_n_rows)\n",
    "    y_index = range(x_n_rows,x_n_rows+y_n_rows)\n",
    "    \n",
    "    # the next part is purely for numerical features - ignore for proteins\n",
    "    Z_num = Z[:,np.logical_not(cat_features)] # may be empty\n",
    "    \n",
    "    num_cols = Z_num.shape[1]\n",
    "    num_ranges = np.zeros(num_cols)\n",
    "    num_max = np.zeros(num_cols)\n",
    "    \n",
    "    \n",
    "    for col in range(num_cols):\n",
    "        col_array = Z_num[:, col].astype(np.float32) \n",
    "        max = np.nanmax(col_array)\n",
    "        min = np.nanmin(col_array)\n",
    "     \n",
    "        if np.isnan(max):\n",
    "            max = 0.0\n",
    "        if np.isnan(min):\n",
    "            min = 0.0\n",
    "        num_max[col] = max\n",
    "        num_ranges[col] = (1 - min / max) if (max != 0) else 0.0\n",
    "\n",
    "    # This is to normalize the numeric values between 0 and 1.\n",
    "    Z_num = np.divide(Z_num ,num_max,out=np.zeros_like(Z_num), where=num_max!=0)\n",
    "    \n",
    "    # now take just the categorical features\n",
    "    Z_cat = Z[:,cat_features]\n",
    "    # the categorical features can be weighed against each other\n",
    "    if weight is None:\n",
    "        weight = np.ones(Z.shape[1])\n",
    "        \n",
    "    #print(weight)    \n",
    "    \n",
    "    weight_cat=weight[cat_features]\n",
    "    weight_num=weight[np.logical_not(cat_features)]   \n",
    "    \n",
    "    # create the output array for everything\n",
    "    out = np.zeros((x_n_rows, y_n_rows), dtype=np.float32)\n",
    "        \n",
    "    weight_sum = weight.sum()\n",
    "    \n",
    "    X_cat = Z_cat[x_index,]\n",
    "    X_num = Z_num[x_index,]\n",
    "    Y_cat = Z_cat[y_index,]\n",
    "    Y_num = Z_num[y_index,]\n",
    "    \n",
    "   # print(X_cat,X_num,Y_cat,Y_num)\n",
    "    \n",
    "    # meat of the function: loop over rows in X\n",
    "    for i in range(x_n_rows):\n",
    "        # the matrix is symmetric\n",
    "        j_start= i        \n",
    "        if x_n_rows != y_n_rows:\n",
    "            j_start = 0\n",
    "        # call the main function\n",
    "        res = blosum_get(X_cat[i,:], \n",
    "                          X_num[i,:],\n",
    "                          Y_cat[j_start:y_n_rows,:],\n",
    "                          Y_num[j_start:y_n_rows,:],\n",
    "                          weight_cat,\n",
    "                          weight_num,\n",
    "                          weight_sum,\n",
    "                          cat_features,\n",
    "                          num_ranges,\n",
    "                          num_max) \n",
    "        #print(res)\n",
    "        out[i,j_start:]=res\n",
    "        if x_n_rows == y_n_rows: out[i:,j_start]=res\n",
    "        \n",
    "    return out\n",
    "\n",
    "def blosum_get(xi_cat,xi_num,xj_cat,xj_num,feature_weight_cat,\n",
    "              feature_weight_num,feature_weight_sum,categorical_features,\n",
    "              ranges_of_numeric,max_of_numeric ):\n",
    "    \n",
    "    # categorical columns\n",
    "    sij_cat = np.where(xi_cat == xj_cat,np.zeros_like(xi_cat),np.ones_like(xi_cat))\n",
    "    sum_cat = np.multiply(feature_weight_cat,sij_cat).sum(axis=1) \n",
    "\n",
    "    # numerical columns\n",
    "    abs_delta=np.absolute(xi_num-xj_num)\n",
    "    sij_num=np.divide(abs_delta, ranges_of_numeric, out=np.zeros_like(abs_delta), where=ranges_of_numeric!=0)\n",
    "\n",
    "    sum_num = np.multiply(feature_weight_num,sij_num).sum(axis=1)\n",
    "    sums= np.add(sum_cat,sum_num)\n",
    "    sum_sij = np.divide(sums,feature_weight_sum)\n",
    "    \n",
    "    return sum_sij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output array for everything\n",
    "out = np.zeros((x_n_rows, y_n_rows), dtype=np.float32)\n",
    "\n",
    "X_cat = Z_cat[x_index,]\n",
    "X_num = Z_num[x_index,]\n",
    "Y_cat = Z_cat[y_index,]\n",
    "Y_num = Z_num[y_index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['6L/7aI/8aA/9L/11F/13M', 'L', 'I', 'A', 'L', 'F', 'M'],\n",
       "       ['6F/7aP/9W/11L/13M', 'F', 'P', 'Δ', 'W', 'L', 'M'],\n",
       "       ['6L/7aF/9L/11I/13I', 'L', 'F', 'Δ', 'L', 'I', 'I'],\n",
       "       ['6A/7aI/8aA/9L/11L/13I', 'A', 'I', 'A', 'L', 'L', 'I'],\n",
       "       ['6W/7aI/9F/11L/13V', 'W', 'I', 'Δ', 'F', 'L', 'V'],\n",
       "       ['6A/7aP/8aA/9L/11V/13W', 'A', 'P', 'A', 'L', 'V', 'W'],\n",
       "       ['6L/7aI/8aA/9M/11W/13W', 'L', 'I', 'A', 'M', 'W', 'W'],\n",
       "       ['6V/7aP/8aA/9F/11F/13M', 'V', 'P', 'A', 'F', 'F', 'M'],\n",
       "       ['6A/7aK/9L/11L/13W', 'A', 'K', 'Δ', 'L', 'L', 'W'],\n",
       "       ['6A/7aI/8aA/9L/11V/13M', 'A', 'I', 'A', 'L', 'V', 'M'],\n",
       "       ['6D/7aI/8aA/9L/11I/13M', 'D', 'I', 'A', 'L', 'I', 'M'],\n",
       "       ['6M/7aP/9L/11L/13V', 'M', 'P', 'Δ', 'L', 'L', 'V'],\n",
       "       ['6L/7aI/9K/11L/13M', 'L', 'I', 'Δ', 'K', 'L', 'M'],\n",
       "       ['6L/7aL/9K/11L/13A', 'L', 'L', 'Δ', 'K', 'L', 'A'],\n",
       "       ['6V/7aI/9D/11L/13W', 'V', 'I', 'Δ', 'D', 'L', 'W'],\n",
       "       ['6L/7aI/8aA/9Y/11M/13V', 'L', 'I', 'A', 'Y', 'M', 'V'],\n",
       "       ['6W/7aP/8aA/9F/11I/13I', 'W', 'P', 'A', 'F', 'I', 'I'],\n",
       "       ['6M/7aP/8aA/9L/11F/13M', 'M', 'P', 'A', 'L', 'F', 'M'],\n",
       "       ['6A/7aG/8aA/9L/11I/13M', 'A', 'G', 'A', 'L', 'I', 'M'],\n",
       "       ['6L/8aA/9L/11L/13W', 'L', 'Δ', 'A', 'L', 'L', 'W'],\n",
       "       ['6F/7aI/9I/11V/13M', 'F', 'I', 'Δ', 'I', 'V', 'M'],\n",
       "       ['6F/7aL/9M/11Y/13W', 'F', 'L', 'Δ', 'M', 'Y', 'W'],\n",
       "       ['6A/7aK/9P/11I/13I', 'A', 'K', 'Δ', 'P', 'I', 'I'],\n",
       "       ['6L/7aI/8aA/9F/11F/13M', 'L', 'I', 'A', 'F', 'F', 'M'],\n",
       "       ['6A/7aP/8aA/9L/11M/13M', 'A', 'P', 'A', 'L', 'M', 'M'],\n",
       "       ['6A/7aI/8aA/9L/11L/13P', 'A', 'I', 'A', 'L', 'L', 'P'],\n",
       "       ['6V/7aM/9I/11L/13M', 'V', 'M', 'Δ', 'I', 'L', 'M'],\n",
       "       ['6W/9L/11L/13I', 'W', 'Δ', 'Δ', 'L', 'L', 'I'],\n",
       "       ['6A/7aY/8aA/9L/11I/13I', 'A', 'Y', 'A', 'L', 'I', 'I'],\n",
       "       ['6D/7aW/9M/11L/13I', 'D', 'W', 'Δ', 'M', 'L', 'I'],\n",
       "       ['6F/7aL/8aA/9M/11Y/13V', 'F', 'L', 'A', 'M', 'Y', 'V'],\n",
       "       ['6D/7aP/8aA/9F/11I/13M', 'D', 'P', 'A', 'F', 'I', 'M'],\n",
       "       ['6L/7aI/8aA/9M/11A/13M', 'L', 'I', 'A', 'M', 'A', 'M'],\n",
       "       ['6A/9P/11L/13W', 'A', 'Δ', 'Δ', 'P', 'L', 'W'],\n",
       "       ['6A/7aI/8aA/9L/11F/13P', 'A', 'I', 'A', 'L', 'F', 'P'],\n",
       "       ['6F/7aL/9L/11F/13V', 'F', 'L', 'Δ', 'L', 'F', 'V'],\n",
       "       ['6A/7aF/8aA/9L/11I/13A', 'A', 'F', 'A', 'L', 'I', 'A'],\n",
       "       ['6K/7aL/8aA/9L/11I/13M', 'K', 'L', 'A', 'L', 'I', 'M'],\n",
       "       ['6L/7aI/8aA/9L/11V/13M', 'L', 'I', 'A', 'L', 'V', 'M'],\n",
       "       ['6V/7aP/9I/11L/13I', 'V', 'P', 'Δ', 'I', 'L', 'I'],\n",
       "       ['6L/7aI/9L/11L/13V', 'L', 'I', 'Δ', 'L', 'L', 'V'],\n",
       "       ['6A/7aD/8aA/9L/11I/13W', 'A', 'D', 'A', 'L', 'I', 'W'],\n",
       "       ['6L/7aI/9L/11P/13W', 'L', 'I', 'Δ', 'L', 'P', 'W'],\n",
       "       ['6M/7aI/8aA/9I/11V/13P', 'M', 'I', 'A', 'I', 'V', 'P'],\n",
       "       ['6F/7aI/8aA/9L/11L/13A', 'F', 'I', 'A', 'L', 'L', 'A'],\n",
       "       ['6A/7aI/9I/11L/13V', 'A', 'I', 'Δ', 'I', 'L', 'V'],\n",
       "       ['6K/7aL/9L/11L/13W', 'K', 'L', 'Δ', 'L', 'L', 'W'],\n",
       "       ['6L/7aL/8aA/9L/11L/13M', 'L', 'L', 'A', 'L', 'L', 'M'],\n",
       "       ['6L/7aI/8aA/9L/11L/13K', 'L', 'I', 'A', 'L', 'L', 'K'],\n",
       "       ['6A/7aP/9K/11L/13I', 'A', 'P', 'Δ', 'K', 'L', 'I'],\n",
       "       ['6M/7aP/8aA/9L/11F/13I', 'M', 'P', 'A', 'L', 'F', 'I'],\n",
       "       ['6P/7aI/8aA/9L/11V/13W', 'P', 'I', 'A', 'L', 'V', 'W'],\n",
       "       ['6Y/7aI/8aA/9L/11F/13W', 'Y', 'I', 'A', 'L', 'F', 'W'],\n",
       "       ['6V/7aK/9P/11L/13W', 'V', 'K', 'Δ', 'P', 'L', 'W'],\n",
       "       ['6Y/7aP/8aA/9L/11I/13A', 'Y', 'P', 'A', 'L', 'I', 'A'],\n",
       "       ['6A/7aK/9K/11L/13W', 'A', 'K', 'Δ', 'K', 'L', 'W'],\n",
       "       ['6W/7aI/9I/11L/13W', 'W', 'I', 'Δ', 'I', 'L', 'W'],\n",
       "       ['6L/7aL/9I/11G/13M', 'L', 'L', 'Δ', 'I', 'G', 'M'],\n",
       "       ['6F/7aL/9I/11F/13G', 'F', 'L', 'Δ', 'I', 'F', 'G'],\n",
       "       ['6I/7aF/8aA/9W/11L/13I', 'I', 'F', 'A', 'W', 'L', 'I'],\n",
       "       ['6F/7aI/8aA/9L/11I/13W', 'F', 'I', 'A', 'L', 'I', 'W'],\n",
       "       ['6V/9K/11L/13W', 'V', 'Δ', 'Δ', 'K', 'L', 'W'],\n",
       "       ['6K/7aF/9I/11L/13W', 'K', 'F', 'Δ', 'I', 'L', 'W'],\n",
       "       ['6W/7aI/8aA/9L/11F/13I', 'W', 'I', 'A', 'L', 'F', 'I'],\n",
       "       ['6F/7aP/8aA/9F/11L/13I', 'F', 'P', 'A', 'F', 'L', 'I'],\n",
       "       ['6W/7aI/8aA/9I/11F/13M', 'W', 'I', 'A', 'I', 'F', 'M'],\n",
       "       ['6I/7aL/9I/11A/13W', 'I', 'L', 'Δ', 'I', 'A', 'W'],\n",
       "       ['6D/7aM/9K/11L/13I', 'D', 'M', 'Δ', 'K', 'L', 'I'],\n",
       "       ['6L/7aF/8aA/9L/11W/13M', 'L', 'F', 'A', 'L', 'W', 'M'],\n",
       "       ['6M/7aI/8aA/9L/11L/13M', 'M', 'I', 'A', 'L', 'L', 'M'],\n",
       "       ['6K/7aL/8aA/9L/11L/13V', 'K', 'L', 'A', 'L', 'L', 'V'],\n",
       "       ['6V/7aP/8aA/9L/11I/13V', 'V', 'P', 'A', 'L', 'I', 'V'],\n",
       "       ['6P/7aK/9K/11L/13I', 'P', 'K', 'Δ', 'K', 'L', 'I'],\n",
       "       ['6A/7aP/9L/11L/13V', 'A', 'P', 'Δ', 'L', 'L', 'V'],\n",
       "       ['6G/7aP/8aA/9L/11L/13P', 'G', 'P', 'A', 'L', 'L', 'P'],\n",
       "       ['6V/9I/11F/13V', 'V', 'Δ', 'Δ', 'I', 'F', 'V'],\n",
       "       ['6L/7aL/9Y/11L/13V', 'L', 'L', 'Δ', 'Y', 'L', 'V'],\n",
       "       ['6M/7aL/9V/11V/13M', 'M', 'L', 'Δ', 'V', 'V', 'M'],\n",
       "       ['6L/7aL/9F/11P/13M', 'L', 'L', 'Δ', 'F', 'P', 'M'],\n",
       "       ['6K/7aF/9K/11L/13W', 'K', 'F', 'Δ', 'K', 'L', 'W'],\n",
       "       ['6L/7aL/9I/11F/13W', 'L', 'L', 'Δ', 'I', 'F', 'W'],\n",
       "       ['6M/7aP/8aA/9L/11L/13W', 'M', 'P', 'A', 'L', 'L', 'W'],\n",
       "       ['6F/7aM/9L/11L/13I', 'F', 'M', 'Δ', 'L', 'L', 'I'],\n",
       "       ['6F/7aI/8aA/9L/11I/13P', 'F', 'I', 'A', 'L', 'I', 'P'],\n",
       "       ['6A/7aY/8aA/9L/11L/13L', 'A', 'Y', 'A', 'L', 'L', 'L'],\n",
       "       ['6F/7aL/9V/11F/13I', 'F', 'L', 'Δ', 'V', 'F', 'I'],\n",
       "       ['6L/7aI/9M/11G/13V', 'L', 'I', 'Δ', 'M', 'G', 'V'],\n",
       "       ['6F/7aL/9M/11F/13A', 'F', 'L', 'Δ', 'M', 'F', 'A'],\n",
       "       ['6G/8aA/9L/11L/13I', 'G', 'Δ', 'A', 'L', 'L', 'I'],\n",
       "       ['6A/7aP/8aA/9L/11Y/13I', 'A', 'P', 'A', 'L', 'Y', 'I'],\n",
       "       ['6L/7aI/8aA/9F/11Y/13A', 'L', 'I', 'A', 'F', 'Y', 'A'],\n",
       "       ['6L/7aL/9V/11L/13L', 'L', 'L', 'Δ', 'V', 'L', 'L'],\n",
       "       ['6Y/7aP/9K/11L/13M', 'Y', 'P', 'Δ', 'K', 'L', 'M'],\n",
       "       ['6F/7aF/8aA/9I/11L/13W', 'F', 'F', 'A', 'I', 'L', 'W'],\n",
       "       ['6F/9L/11L/13M', 'F', 'Δ', 'Δ', 'L', 'L', 'M'],\n",
       "       ['6L/7aI/8aA/9M/11M/13M', 'L', 'I', 'A', 'M', 'M', 'M'],\n",
       "       ['6W/7aK/9L/11F/13M', 'W', 'K', 'Δ', 'L', 'F', 'M'],\n",
       "       ['6W/7aP/8aA/9L/11L/13M', 'W', 'P', 'A', 'L', 'L', 'M'],\n",
       "       ['6P/7aL/9K/11V/13W', 'P', 'L', 'Δ', 'K', 'V', 'W'],\n",
       "       ['6I/7aI/8aA/9L/11F/13A', 'I', 'I', 'A', 'L', 'F', 'A']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
